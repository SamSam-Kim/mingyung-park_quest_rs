{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02d54c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0624bb11",
   "metadata": {},
   "source": [
    "# Data Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5d758b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "708cd52e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 10)\n",
      "(442,)\n"
     ]
    }
   ],
   "source": [
    "df_x = diabetes.data\n",
    "df_y = diabetes.target\n",
    "print(df_x.shape)\n",
    "print(df_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400c7b22",
   "metadata": {},
   "source": [
    "# Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfb7446d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(df_x)\n",
    "y = np.array(df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3aec0b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(353, 10) (353,)\n",
      "(89, 10) (89,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape,y_train.shape)\n",
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9024c688",
   "metadata": {},
   "source": [
    "# 모델 가중치 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "210ce5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4330641  0.64942309 0.12016298 0.57533752 0.2684388  0.71600683\n",
      " 0.82062898 0.81469426 0.19703349 0.82856756] 0.7781921960449837\n"
     ]
    }
   ],
   "source": [
    "W = np.random.rand(10)\n",
    "b = np.random.rand()\n",
    "print(W,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "980258df",
   "metadata": {},
   "source": [
    "# Model, Loss, Gradient 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59c524b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, W, b):\n",
    "    predictions = 0\n",
    "    for i in range(10):\n",
    "        predictions += X[:, i] * W[i]\n",
    "    predictions += b\n",
    "    return predictions\n",
    "\n",
    "def MSE(a, b):\n",
    "    mse = ((a - b) ** 2).mean()  \n",
    "    return mse\n",
    "\n",
    "def loss(X, W, b, y):\n",
    "    predictions = model(X, W, b)\n",
    "    L = MSE(predictions, y)\n",
    "    return L\n",
    "\n",
    "def gradient(X, W, b, y):\n",
    "    N = len(y)\n",
    "    y_pred = model(X, W, b)\n",
    "    dW = 1/N * 2 * X.T.dot(y_pred - y)\n",
    "    db = 2 * (y_pred - y).mean()\n",
    "    return dW, db"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e821041",
   "metadata": {},
   "source": [
    "# 학습률 설정하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fbe7b84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.05"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a615b9",
   "metadata": {},
   "source": [
    "# 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cadf7ee5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10 : Loss 8869.7430\n",
      "Iteration 20 : Loss 6331.9352\n",
      "Iteration 30 : Loss 5989.8563\n",
      "Iteration 40 : Loss 5915.2447\n",
      "Iteration 50 : Loss 5873.6669\n",
      "Iteration 60 : Loss 5836.6133\n",
      "Iteration 70 : Loss 5800.6092\n",
      "Iteration 80 : Loss 5765.2237\n",
      "Iteration 90 : Loss 5730.3959\n",
      "Iteration 100 : Loss 5696.1102\n",
      "Iteration 110 : Loss 5662.3566\n",
      "Iteration 120 : Loss 5629.1259\n",
      "Iteration 130 : Loss 5596.4091\n",
      "Iteration 140 : Loss 5564.1976\n",
      "Iteration 150 : Loss 5532.4827\n",
      "Iteration 160 : Loss 5501.2558\n",
      "Iteration 170 : Loss 5470.5088\n",
      "Iteration 180 : Loss 5440.2335\n",
      "Iteration 190 : Loss 5410.4217\n",
      "Iteration 200 : Loss 5381.0657\n",
      "Iteration 210 : Loss 5352.1576\n",
      "Iteration 220 : Loss 5323.6900\n",
      "Iteration 230 : Loss 5295.6552\n",
      "Iteration 240 : Loss 5268.0461\n",
      "Iteration 250 : Loss 5240.8552\n",
      "Iteration 260 : Loss 5214.0757\n",
      "Iteration 270 : Loss 5187.7004\n",
      "Iteration 280 : Loss 5161.7226\n",
      "Iteration 290 : Loss 5136.1356\n",
      "Iteration 300 : Loss 5110.9326\n",
      "Iteration 310 : Loss 5086.1074\n",
      "Iteration 320 : Loss 5061.6534\n",
      "Iteration 330 : Loss 5037.5644\n",
      "Iteration 340 : Loss 5013.8343\n",
      "Iteration 350 : Loss 4990.4571\n",
      "Iteration 360 : Loss 4967.4267\n",
      "Iteration 370 : Loss 4944.7374\n",
      "Iteration 380 : Loss 4922.3834\n",
      "Iteration 390 : Loss 4900.3591\n",
      "Iteration 400 : Loss 4878.6590\n",
      "Iteration 410 : Loss 4857.2776\n",
      "Iteration 420 : Loss 4836.2097\n",
      "Iteration 430 : Loss 4815.4498\n",
      "Iteration 440 : Loss 4794.9930\n",
      "Iteration 450 : Loss 4774.8341\n",
      "Iteration 460 : Loss 4754.9681\n",
      "Iteration 470 : Loss 4735.3902\n",
      "Iteration 480 : Loss 4716.0956\n",
      "Iteration 490 : Loss 4697.0795\n",
      "Iteration 500 : Loss 4678.3374\n",
      "Iteration 510 : Loss 4659.8645\n",
      "Iteration 520 : Loss 4641.6566\n",
      "Iteration 530 : Loss 4623.7092\n",
      "Iteration 540 : Loss 4606.0179\n",
      "Iteration 550 : Loss 4588.5785\n",
      "Iteration 560 : Loss 4571.3869\n",
      "Iteration 570 : Loss 4554.4389\n",
      "Iteration 580 : Loss 4537.7306\n",
      "Iteration 590 : Loss 4521.2579\n",
      "Iteration 600 : Loss 4505.0170\n",
      "Iteration 610 : Loss 4489.0040\n",
      "Iteration 620 : Loss 4473.2153\n",
      "Iteration 630 : Loss 4457.6470\n",
      "Iteration 640 : Loss 4442.2957\n",
      "Iteration 650 : Loss 4427.1577\n",
      "Iteration 660 : Loss 4412.2295\n",
      "Iteration 670 : Loss 4397.5077\n",
      "Iteration 680 : Loss 4382.9889\n",
      "Iteration 690 : Loss 4368.6698\n",
      "Iteration 700 : Loss 4354.5472\n",
      "Iteration 710 : Loss 4340.6177\n",
      "Iteration 720 : Loss 4326.8784\n",
      "Iteration 730 : Loss 4313.3260\n",
      "Iteration 740 : Loss 4299.9576\n",
      "Iteration 750 : Loss 4286.7701\n",
      "Iteration 760 : Loss 4273.7607\n",
      "Iteration 770 : Loss 4260.9264\n",
      "Iteration 780 : Loss 4248.2644\n",
      "Iteration 790 : Loss 4235.7718\n",
      "Iteration 800 : Loss 4223.4461\n",
      "Iteration 810 : Loss 4211.2844\n",
      "Iteration 820 : Loss 4199.2842\n",
      "Iteration 830 : Loss 4187.4428\n",
      "Iteration 840 : Loss 4175.7577\n",
      "Iteration 850 : Loss 4164.2263\n",
      "Iteration 860 : Loss 4152.8463\n",
      "Iteration 870 : Loss 4141.6151\n",
      "Iteration 880 : Loss 4130.5304\n",
      "Iteration 890 : Loss 4119.5899\n",
      "Iteration 900 : Loss 4108.7913\n",
      "Iteration 910 : Loss 4098.1322\n",
      "Iteration 920 : Loss 4087.6106\n",
      "Iteration 930 : Loss 4077.2241\n",
      "Iteration 940 : Loss 4066.9706\n",
      "Iteration 950 : Loss 4056.8481\n",
      "Iteration 960 : Loss 4046.8544\n",
      "Iteration 970 : Loss 4036.9876\n",
      "Iteration 980 : Loss 4027.2456\n",
      "Iteration 990 : Loss 4017.6265\n",
      "Iteration 1000 : Loss 4008.1282\n",
      "Iteration 1010 : Loss 3998.7490\n",
      "Iteration 1020 : Loss 3989.4869\n",
      "Iteration 1030 : Loss 3980.3402\n",
      "Iteration 1040 : Loss 3971.3069\n",
      "Iteration 1050 : Loss 3962.3854\n",
      "Iteration 1060 : Loss 3953.5739\n",
      "Iteration 1070 : Loss 3944.8707\n",
      "Iteration 1080 : Loss 3936.2740\n",
      "Iteration 1090 : Loss 3927.7823\n",
      "Iteration 1100 : Loss 3919.3939\n",
      "Iteration 1110 : Loss 3911.1072\n",
      "Iteration 1120 : Loss 3902.9206\n",
      "Iteration 1130 : Loss 3894.8326\n",
      "Iteration 1140 : Loss 3886.8417\n",
      "Iteration 1150 : Loss 3878.9464\n",
      "Iteration 1160 : Loss 3871.1451\n",
      "Iteration 1170 : Loss 3863.4366\n",
      "Iteration 1180 : Loss 3855.8193\n",
      "Iteration 1190 : Loss 3848.2918\n",
      "Iteration 1200 : Loss 3840.8528\n",
      "Iteration 1210 : Loss 3833.5010\n",
      "Iteration 1220 : Loss 3826.2349\n",
      "Iteration 1230 : Loss 3819.0534\n",
      "Iteration 1240 : Loss 3811.9551\n",
      "Iteration 1250 : Loss 3804.9387\n",
      "Iteration 1260 : Loss 3798.0031\n",
      "Iteration 1270 : Loss 3791.1470\n",
      "Iteration 1280 : Loss 3784.3692\n",
      "Iteration 1290 : Loss 3777.6686\n",
      "Iteration 1300 : Loss 3771.0439\n",
      "Iteration 1310 : Loss 3764.4941\n",
      "Iteration 1320 : Loss 3758.0180\n",
      "Iteration 1330 : Loss 3751.6145\n",
      "Iteration 1340 : Loss 3745.2827\n",
      "Iteration 1350 : Loss 3739.0212\n",
      "Iteration 1360 : Loss 3732.8293\n",
      "Iteration 1370 : Loss 3726.7057\n",
      "Iteration 1380 : Loss 3720.6496\n",
      "Iteration 1390 : Loss 3714.6599\n",
      "Iteration 1400 : Loss 3708.7356\n",
      "Iteration 1410 : Loss 3702.8759\n",
      "Iteration 1420 : Loss 3697.0796\n",
      "Iteration 1430 : Loss 3691.3460\n",
      "Iteration 1440 : Loss 3685.6740\n",
      "Iteration 1450 : Loss 3680.0629\n",
      "Iteration 1460 : Loss 3674.5117\n",
      "Iteration 1470 : Loss 3669.0196\n",
      "Iteration 1480 : Loss 3663.5856\n",
      "Iteration 1490 : Loss 3658.2090\n",
      "Iteration 1500 : Loss 3652.8890\n",
      "Iteration 1510 : Loss 3647.6246\n",
      "Iteration 1520 : Loss 3642.4152\n",
      "Iteration 1530 : Loss 3637.2600\n",
      "Iteration 1540 : Loss 3632.1581\n",
      "Iteration 1550 : Loss 3627.1088\n",
      "Iteration 1560 : Loss 3622.1114\n",
      "Iteration 1570 : Loss 3617.1651\n",
      "Iteration 1580 : Loss 3612.2693\n",
      "Iteration 1590 : Loss 3607.4231\n",
      "Iteration 1600 : Loss 3602.6259\n",
      "Iteration 1610 : Loss 3597.8771\n",
      "Iteration 1620 : Loss 3593.1759\n",
      "Iteration 1630 : Loss 3588.5217\n",
      "Iteration 1640 : Loss 3583.9138\n",
      "Iteration 1650 : Loss 3579.3516\n",
      "Iteration 1660 : Loss 3574.8344\n",
      "Iteration 1670 : Loss 3570.3617\n",
      "Iteration 1680 : Loss 3565.9327\n",
      "Iteration 1690 : Loss 3561.5470\n",
      "Iteration 1700 : Loss 3557.2039\n",
      "Iteration 1710 : Loss 3552.9029\n",
      "Iteration 1720 : Loss 3548.6433\n",
      "Iteration 1730 : Loss 3544.4246\n",
      "Iteration 1740 : Loss 3540.2462\n",
      "Iteration 1750 : Loss 3536.1077\n",
      "Iteration 1760 : Loss 3532.0084\n",
      "Iteration 1770 : Loss 3527.9479\n",
      "Iteration 1780 : Loss 3523.9255\n",
      "Iteration 1790 : Loss 3519.9409\n",
      "Iteration 1800 : Loss 3515.9935\n",
      "Iteration 1810 : Loss 3512.0828\n",
      "Iteration 1820 : Loss 3508.2083\n",
      "Iteration 1830 : Loss 3504.3696\n",
      "Iteration 1840 : Loss 3500.5661\n",
      "Iteration 1850 : Loss 3496.7975\n",
      "Iteration 1860 : Loss 3493.0632\n",
      "Iteration 1870 : Loss 3489.3628\n",
      "Iteration 1880 : Loss 3485.6958\n",
      "Iteration 1890 : Loss 3482.0619\n",
      "Iteration 1900 : Loss 3478.4606\n",
      "Iteration 1910 : Loss 3474.8914\n",
      "Iteration 1920 : Loss 3471.3541\n",
      "Iteration 1930 : Loss 3467.8480\n",
      "Iteration 1940 : Loss 3464.3730\n",
      "Iteration 1950 : Loss 3460.9285\n",
      "Iteration 1960 : Loss 3457.5141\n",
      "Iteration 1970 : Loss 3454.1296\n",
      "Iteration 1980 : Loss 3450.7744\n",
      "Iteration 1990 : Loss 3447.4483\n",
      "Iteration 2000 : Loss 3444.1509\n",
      "Iteration 2010 : Loss 3440.8818\n",
      "Iteration 2020 : Loss 3437.6406\n",
      "Iteration 2030 : Loss 3434.4271\n",
      "Iteration 2040 : Loss 3431.2408\n",
      "Iteration 2050 : Loss 3428.0815\n",
      "Iteration 2060 : Loss 3424.9487\n",
      "Iteration 2070 : Loss 3421.8423\n",
      "Iteration 2080 : Loss 3418.7618\n",
      "Iteration 2090 : Loss 3415.7069\n",
      "Iteration 2100 : Loss 3412.6773\n",
      "Iteration 2110 : Loss 3409.6728\n",
      "Iteration 2120 : Loss 3406.6930\n",
      "Iteration 2130 : Loss 3403.7376\n",
      "Iteration 2140 : Loss 3400.8063\n",
      "Iteration 2150 : Loss 3397.8989\n",
      "Iteration 2160 : Loss 3395.0150\n",
      "Iteration 2170 : Loss 3392.1543\n",
      "Iteration 2180 : Loss 3389.3167\n",
      "Iteration 2190 : Loss 3386.5018\n",
      "Iteration 2200 : Loss 3383.7093\n",
      "Iteration 2210 : Loss 3380.9391\n",
      "Iteration 2220 : Loss 3378.1908\n",
      "Iteration 2230 : Loss 3375.4641\n",
      "Iteration 2240 : Loss 3372.7589\n",
      "Iteration 2250 : Loss 3370.0749\n",
      "Iteration 2260 : Loss 3367.4118\n",
      "Iteration 2270 : Loss 3364.7693\n",
      "Iteration 2280 : Loss 3362.1474\n",
      "Iteration 2290 : Loss 3359.5457\n",
      "Iteration 2300 : Loss 3356.9639\n",
      "Iteration 2310 : Loss 3354.4020\n",
      "Iteration 2320 : Loss 3351.8595\n",
      "Iteration 2330 : Loss 3349.3364\n",
      "Iteration 2340 : Loss 3346.8325\n",
      "Iteration 2350 : Loss 3344.3474\n",
      "Iteration 2360 : Loss 3341.8810\n",
      "Iteration 2370 : Loss 3339.4330\n",
      "Iteration 2380 : Loss 3337.0034\n",
      "Iteration 2390 : Loss 3334.5918\n",
      "Iteration 2400 : Loss 3332.1981\n",
      "Iteration 2410 : Loss 3329.8221\n",
      "Iteration 2420 : Loss 3327.4636\n",
      "Iteration 2430 : Loss 3325.1224\n",
      "Iteration 2440 : Loss 3322.7983\n",
      "Iteration 2450 : Loss 3320.4911\n",
      "Iteration 2460 : Loss 3318.2006\n",
      "Iteration 2470 : Loss 3315.9268\n",
      "Iteration 2480 : Loss 3313.6693\n",
      "Iteration 2490 : Loss 3311.4281\n",
      "Iteration 2500 : Loss 3309.2029\n",
      "Iteration 2510 : Loss 3306.9935\n",
      "Iteration 2520 : Loss 3304.7999\n",
      "Iteration 2530 : Loss 3302.6219\n",
      "Iteration 2540 : Loss 3300.4592\n",
      "Iteration 2550 : Loss 3298.3118\n",
      "Iteration 2560 : Loss 3296.1794\n",
      "Iteration 2570 : Loss 3294.0619\n",
      "Iteration 2580 : Loss 3291.9592\n",
      "Iteration 2590 : Loss 3289.8712\n",
      "Iteration 2600 : Loss 3287.7976\n",
      "Iteration 2610 : Loss 3285.7383\n",
      "Iteration 2620 : Loss 3283.6932\n",
      "Iteration 2630 : Loss 3281.6621\n",
      "Iteration 2640 : Loss 3279.6449\n",
      "Iteration 2650 : Loss 3277.6415\n",
      "Iteration 2660 : Loss 3275.6516\n",
      "Iteration 2670 : Loss 3273.6753\n",
      "Iteration 2680 : Loss 3271.7123\n",
      "Iteration 2690 : Loss 3269.7626\n",
      "Iteration 2700 : Loss 3267.8259\n",
      "Iteration 2710 : Loss 3265.9022\n",
      "Iteration 2720 : Loss 3263.9913\n",
      "Iteration 2730 : Loss 3262.0931\n",
      "Iteration 2740 : Loss 3260.2076\n",
      "Iteration 2750 : Loss 3258.3345\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 2760 : Loss 3256.4737\n",
      "Iteration 2770 : Loss 3254.6252\n",
      "Iteration 2780 : Loss 3252.7888\n",
      "Iteration 2790 : Loss 3250.9644\n",
      "Iteration 2800 : Loss 3249.1519\n",
      "Iteration 2810 : Loss 3247.3512\n",
      "Iteration 2820 : Loss 3245.5621\n",
      "Iteration 2830 : Loss 3243.7846\n",
      "Iteration 2840 : Loss 3242.0186\n",
      "Iteration 2850 : Loss 3240.2639\n",
      "Iteration 2860 : Loss 3238.5205\n",
      "Iteration 2870 : Loss 3236.7882\n",
      "Iteration 2880 : Loss 3235.0669\n",
      "Iteration 2890 : Loss 3233.3566\n",
      "Iteration 2900 : Loss 3231.6571\n",
      "Iteration 2910 : Loss 3229.9684\n",
      "Iteration 2920 : Loss 3228.2903\n",
      "Iteration 2930 : Loss 3226.6227\n",
      "Iteration 2940 : Loss 3224.9656\n",
      "Iteration 2950 : Loss 3223.3189\n",
      "Iteration 2960 : Loss 3221.6825\n",
      "Iteration 2970 : Loss 3220.0562\n",
      "Iteration 2980 : Loss 3218.4401\n",
      "Iteration 2990 : Loss 3216.8339\n",
      "Iteration 3000 : Loss 3215.2377\n",
      "Iteration 3010 : Loss 3213.6513\n",
      "Iteration 3020 : Loss 3212.0746\n",
      "Iteration 3030 : Loss 3210.5076\n",
      "Iteration 3040 : Loss 3208.9502\n",
      "Iteration 3050 : Loss 3207.4023\n",
      "Iteration 3060 : Loss 3205.8638\n",
      "Iteration 3070 : Loss 3204.3347\n",
      "Iteration 3080 : Loss 3202.8148\n",
      "Iteration 3090 : Loss 3201.3041\n",
      "Iteration 3100 : Loss 3199.8025\n",
      "Iteration 3110 : Loss 3198.3099\n",
      "Iteration 3120 : Loss 3196.8263\n",
      "Iteration 3130 : Loss 3195.3516\n",
      "Iteration 3140 : Loss 3193.8857\n",
      "Iteration 3150 : Loss 3192.4285\n",
      "Iteration 3160 : Loss 3190.9800\n",
      "Iteration 3170 : Loss 3189.5400\n",
      "Iteration 3180 : Loss 3188.1086\n",
      "Iteration 3190 : Loss 3186.6857\n",
      "Iteration 3200 : Loss 3185.2711\n",
      "Iteration 3210 : Loss 3183.8649\n",
      "Iteration 3220 : Loss 3182.4669\n",
      "Iteration 3230 : Loss 3181.0771\n",
      "Iteration 3240 : Loss 3179.6954\n",
      "Iteration 3250 : Loss 3178.3217\n",
      "Iteration 3260 : Loss 3176.9561\n",
      "Iteration 3270 : Loss 3175.5984\n",
      "Iteration 3280 : Loss 3174.2486\n",
      "Iteration 3290 : Loss 3172.9065\n",
      "Iteration 3300 : Loss 3171.5722\n",
      "Iteration 3310 : Loss 3170.2456\n",
      "Iteration 3320 : Loss 3168.9267\n",
      "Iteration 3330 : Loss 3167.6153\n",
      "Iteration 3340 : Loss 3166.3114\n",
      "Iteration 3350 : Loss 3165.0149\n",
      "Iteration 3360 : Loss 3163.7259\n",
      "Iteration 3370 : Loss 3162.4442\n",
      "Iteration 3380 : Loss 3161.1698\n",
      "Iteration 3390 : Loss 3159.9026\n",
      "Iteration 3400 : Loss 3158.6425\n",
      "Iteration 3410 : Loss 3157.3896\n",
      "Iteration 3420 : Loss 3156.1438\n",
      "Iteration 3430 : Loss 3154.9050\n",
      "Iteration 3440 : Loss 3153.6731\n",
      "Iteration 3450 : Loss 3152.4482\n",
      "Iteration 3460 : Loss 3151.2301\n",
      "Iteration 3470 : Loss 3150.0189\n",
      "Iteration 3480 : Loss 3148.8144\n",
      "Iteration 3490 : Loss 3147.6166\n",
      "Iteration 3500 : Loss 3146.4254\n",
      "Iteration 3510 : Loss 3145.2409\n",
      "Iteration 3520 : Loss 3144.0630\n",
      "Iteration 3530 : Loss 3142.8915\n",
      "Iteration 3540 : Loss 3141.7266\n",
      "Iteration 3550 : Loss 3140.5680\n",
      "Iteration 3560 : Loss 3139.4159\n",
      "Iteration 3570 : Loss 3138.2701\n",
      "Iteration 3580 : Loss 3137.1305\n",
      "Iteration 3590 : Loss 3135.9972\n",
      "Iteration 3600 : Loss 3134.8702\n",
      "Iteration 3610 : Loss 3133.7492\n",
      "Iteration 3620 : Loss 3132.6344\n",
      "Iteration 3630 : Loss 3131.5257\n",
      "Iteration 3640 : Loss 3130.4230\n",
      "Iteration 3650 : Loss 3129.3263\n",
      "Iteration 3660 : Loss 3128.2355\n",
      "Iteration 3670 : Loss 3127.1507\n",
      "Iteration 3680 : Loss 3126.0717\n",
      "Iteration 3690 : Loss 3124.9985\n",
      "Iteration 3700 : Loss 3123.9311\n",
      "Iteration 3710 : Loss 3122.8695\n",
      "Iteration 3720 : Loss 3121.8135\n",
      "Iteration 3730 : Loss 3120.7633\n",
      "Iteration 3740 : Loss 3119.7186\n",
      "Iteration 3750 : Loss 3118.6796\n",
      "Iteration 3760 : Loss 3117.6461\n",
      "Iteration 3770 : Loss 3116.6181\n",
      "Iteration 3780 : Loss 3115.5957\n",
      "Iteration 3790 : Loss 3114.5786\n",
      "Iteration 3800 : Loss 3113.5670\n",
      "Iteration 3810 : Loss 3112.5607\n",
      "Iteration 3820 : Loss 3111.5598\n",
      "Iteration 3830 : Loss 3110.5642\n",
      "Iteration 3840 : Loss 3109.5738\n",
      "Iteration 3850 : Loss 3108.5887\n",
      "Iteration 3860 : Loss 3107.6088\n",
      "Iteration 3870 : Loss 3106.6340\n",
      "Iteration 3880 : Loss 3105.6644\n",
      "Iteration 3890 : Loss 3104.6998\n",
      "Iteration 3900 : Loss 3103.7404\n",
      "Iteration 3910 : Loss 3102.7859\n",
      "Iteration 3920 : Loss 3101.8365\n",
      "Iteration 3930 : Loss 3100.8920\n",
      "Iteration 3940 : Loss 3099.9525\n",
      "Iteration 3950 : Loss 3099.0179\n",
      "Iteration 3960 : Loss 3098.0881\n",
      "Iteration 3970 : Loss 3097.1632\n",
      "Iteration 3980 : Loss 3096.2431\n",
      "Iteration 3990 : Loss 3095.3278\n",
      "Iteration 4000 : Loss 3094.4172\n",
      "Iteration 4010 : Loss 3093.5114\n",
      "Iteration 4020 : Loss 3092.6102\n",
      "Iteration 4030 : Loss 3091.7137\n",
      "Iteration 4040 : Loss 3090.8219\n",
      "Iteration 4050 : Loss 3089.9346\n",
      "Iteration 4060 : Loss 3089.0519\n",
      "Iteration 4070 : Loss 3088.1738\n",
      "Iteration 4080 : Loss 3087.3002\n",
      "Iteration 4090 : Loss 3086.4310\n",
      "Iteration 4100 : Loss 3085.5664\n",
      "Iteration 4110 : Loss 3084.7062\n",
      "Iteration 4120 : Loss 3083.8503\n",
      "Iteration 4130 : Loss 3082.9989\n",
      "Iteration 4140 : Loss 3082.1518\n",
      "Iteration 4150 : Loss 3081.3091\n",
      "Iteration 4160 : Loss 3080.4706\n",
      "Iteration 4170 : Loss 3079.6365\n",
      "Iteration 4180 : Loss 3078.8065\n",
      "Iteration 4190 : Loss 3077.9808\n",
      "Iteration 4200 : Loss 3077.1593\n",
      "Iteration 4210 : Loss 3076.3420\n",
      "Iteration 4220 : Loss 3075.5288\n",
      "Iteration 4230 : Loss 3074.7198\n",
      "Iteration 4240 : Loss 3073.9148\n",
      "Iteration 4250 : Loss 3073.1139\n",
      "Iteration 4260 : Loss 3072.3171\n",
      "Iteration 4270 : Loss 3071.5243\n",
      "Iteration 4280 : Loss 3070.7355\n",
      "Iteration 4290 : Loss 3069.9507\n",
      "Iteration 4300 : Loss 3069.1698\n",
      "Iteration 4310 : Loss 3068.3929\n",
      "Iteration 4320 : Loss 3067.6199\n",
      "Iteration 4330 : Loss 3066.8508\n",
      "Iteration 4340 : Loss 3066.0855\n",
      "Iteration 4350 : Loss 3065.3240\n",
      "Iteration 4360 : Loss 3064.5664\n",
      "Iteration 4370 : Loss 3063.8126\n",
      "Iteration 4380 : Loss 3063.0626\n",
      "Iteration 4390 : Loss 3062.3163\n",
      "Iteration 4400 : Loss 3061.5737\n",
      "Iteration 4410 : Loss 3060.8349\n",
      "Iteration 4420 : Loss 3060.0997\n",
      "Iteration 4430 : Loss 3059.3682\n",
      "Iteration 4440 : Loss 3058.6403\n",
      "Iteration 4450 : Loss 3057.9161\n",
      "Iteration 4460 : Loss 3057.1955\n",
      "Iteration 4470 : Loss 3056.4784\n",
      "Iteration 4480 : Loss 3055.7649\n",
      "Iteration 4490 : Loss 3055.0550\n",
      "Iteration 4500 : Loss 3054.3486\n",
      "Iteration 4510 : Loss 3053.6457\n",
      "Iteration 4520 : Loss 3052.9462\n",
      "Iteration 4530 : Loss 3052.2502\n",
      "Iteration 4540 : Loss 3051.5577\n",
      "Iteration 4550 : Loss 3050.8686\n",
      "Iteration 4560 : Loss 3050.1829\n",
      "Iteration 4570 : Loss 3049.5006\n",
      "Iteration 4580 : Loss 3048.8216\n",
      "Iteration 4590 : Loss 3048.1460\n",
      "Iteration 4600 : Loss 3047.4737\n",
      "Iteration 4610 : Loss 3046.8047\n",
      "Iteration 4620 : Loss 3046.1390\n",
      "Iteration 4630 : Loss 3045.4766\n",
      "Iteration 4640 : Loss 3044.8174\n",
      "Iteration 4650 : Loss 3044.1615\n",
      "Iteration 4660 : Loss 3043.5088\n",
      "Iteration 4670 : Loss 3042.8593\n",
      "Iteration 4680 : Loss 3042.2130\n",
      "Iteration 4690 : Loss 3041.5698\n",
      "Iteration 4700 : Loss 3040.9298\n",
      "Iteration 4710 : Loss 3040.2929\n",
      "Iteration 4720 : Loss 3039.6591\n",
      "Iteration 4730 : Loss 3039.0284\n",
      "Iteration 4740 : Loss 3038.4008\n",
      "Iteration 4750 : Loss 3037.7763\n",
      "Iteration 4760 : Loss 3037.1548\n",
      "Iteration 4770 : Loss 3036.5363\n",
      "Iteration 4780 : Loss 3035.9208\n",
      "Iteration 4790 : Loss 3035.3083\n",
      "Iteration 4800 : Loss 3034.6989\n",
      "Iteration 4810 : Loss 3034.0923\n",
      "Iteration 4820 : Loss 3033.4887\n",
      "Iteration 4830 : Loss 3032.8881\n",
      "Iteration 4840 : Loss 3032.2903\n",
      "Iteration 4850 : Loss 3031.6955\n",
      "Iteration 4860 : Loss 3031.1035\n",
      "Iteration 4870 : Loss 3030.5144\n",
      "Iteration 4880 : Loss 3029.9282\n",
      "Iteration 4890 : Loss 3029.3448\n",
      "Iteration 4900 : Loss 3028.7642\n",
      "Iteration 4910 : Loss 3028.1864\n",
      "Iteration 4920 : Loss 3027.6114\n",
      "Iteration 4930 : Loss 3027.0392\n",
      "Iteration 4940 : Loss 3026.4697\n",
      "Iteration 4950 : Loss 3025.9030\n",
      "Iteration 4960 : Loss 3025.3390\n",
      "Iteration 4970 : Loss 3024.7777\n",
      "Iteration 4980 : Loss 3024.2192\n",
      "Iteration 4990 : Loss 3023.6633\n",
      "Iteration 5000 : Loss 3023.1101\n",
      "Iteration 5010 : Loss 3022.5595\n",
      "Iteration 5020 : Loss 3022.0116\n",
      "Iteration 5030 : Loss 3021.4663\n",
      "Iteration 5040 : Loss 3020.9237\n",
      "Iteration 5050 : Loss 3020.3836\n",
      "Iteration 5060 : Loss 3019.8461\n",
      "Iteration 5070 : Loss 3019.3112\n",
      "Iteration 5080 : Loss 3018.7789\n",
      "Iteration 5090 : Loss 3018.2491\n",
      "Iteration 5100 : Loss 3017.7219\n",
      "Iteration 5110 : Loss 3017.1971\n",
      "Iteration 5120 : Loss 3016.6749\n",
      "Iteration 5130 : Loss 3016.1552\n",
      "Iteration 5140 : Loss 3015.6379\n",
      "Iteration 5150 : Loss 3015.1231\n",
      "Iteration 5160 : Loss 3014.6108\n",
      "Iteration 5170 : Loss 3014.1009\n",
      "Iteration 5180 : Loss 3013.5934\n",
      "Iteration 5190 : Loss 3013.0884\n",
      "Iteration 5200 : Loss 3012.5858\n",
      "Iteration 5210 : Loss 3012.0855\n",
      "Iteration 5220 : Loss 3011.5876\n",
      "Iteration 5230 : Loss 3011.0921\n",
      "Iteration 5240 : Loss 3010.5990\n",
      "Iteration 5250 : Loss 3010.1082\n",
      "Iteration 5260 : Loss 3009.6197\n",
      "Iteration 5270 : Loss 3009.1335\n",
      "Iteration 5280 : Loss 3008.6497\n",
      "Iteration 5290 : Loss 3008.1681\n",
      "Iteration 5300 : Loss 3007.6888\n",
      "Iteration 5310 : Loss 3007.2118\n",
      "Iteration 5320 : Loss 3006.7371\n",
      "Iteration 5330 : Loss 3006.2646\n",
      "Iteration 5340 : Loss 3005.7943\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 5350 : Loss 3005.3262\n",
      "Iteration 5360 : Loss 3004.8604\n",
      "Iteration 5370 : Loss 3004.3968\n",
      "Iteration 5380 : Loss 3003.9353\n",
      "Iteration 5390 : Loss 3003.4760\n",
      "Iteration 5400 : Loss 3003.0189\n",
      "Iteration 5410 : Loss 3002.5640\n",
      "Iteration 5420 : Loss 3002.1112\n",
      "Iteration 5430 : Loss 3001.6605\n",
      "Iteration 5440 : Loss 3001.2119\n",
      "Iteration 5450 : Loss 3000.7655\n",
      "Iteration 5460 : Loss 3000.3212\n",
      "Iteration 5470 : Loss 2999.8789\n",
      "Iteration 5480 : Loss 2999.4387\n",
      "Iteration 5490 : Loss 2999.0006\n",
      "Iteration 5500 : Loss 2998.5646\n",
      "Iteration 5510 : Loss 2998.1306\n",
      "Iteration 5520 : Loss 2997.6986\n",
      "Iteration 5530 : Loss 2997.2687\n",
      "Iteration 5540 : Loss 2996.8407\n",
      "Iteration 5550 : Loss 2996.4148\n",
      "Iteration 5560 : Loss 2995.9909\n",
      "Iteration 5570 : Loss 2995.5690\n",
      "Iteration 5580 : Loss 2995.1490\n",
      "Iteration 5590 : Loss 2994.7310\n",
      "Iteration 5600 : Loss 2994.3150\n",
      "Iteration 5610 : Loss 2993.9009\n",
      "Iteration 5620 : Loss 2993.4887\n",
      "Iteration 5630 : Loss 2993.0785\n",
      "Iteration 5640 : Loss 2992.6701\n",
      "Iteration 5650 : Loss 2992.2637\n",
      "Iteration 5660 : Loss 2991.8592\n",
      "Iteration 5670 : Loss 2991.4566\n",
      "Iteration 5680 : Loss 2991.0558\n",
      "Iteration 5690 : Loss 2990.6569\n",
      "Iteration 5700 : Loss 2990.2599\n",
      "Iteration 5710 : Loss 2989.8647\n",
      "Iteration 5720 : Loss 2989.4714\n",
      "Iteration 5730 : Loss 2989.0799\n",
      "Iteration 5740 : Loss 2988.6902\n",
      "Iteration 5750 : Loss 2988.3023\n",
      "Iteration 5760 : Loss 2987.9162\n",
      "Iteration 5770 : Loss 2987.5319\n",
      "Iteration 5780 : Loss 2987.1494\n",
      "Iteration 5790 : Loss 2986.7687\n",
      "Iteration 5800 : Loss 2986.3898\n",
      "Iteration 5810 : Loss 2986.0126\n",
      "Iteration 5820 : Loss 2985.6371\n",
      "Iteration 5830 : Loss 2985.2634\n",
      "Iteration 5840 : Loss 2984.8914\n",
      "Iteration 5850 : Loss 2984.5212\n",
      "Iteration 5860 : Loss 2984.1527\n",
      "Iteration 5870 : Loss 2983.7858\n",
      "Iteration 5880 : Loss 2983.4207\n",
      "Iteration 5890 : Loss 2983.0572\n",
      "Iteration 5900 : Loss 2982.6955\n",
      "Iteration 5910 : Loss 2982.3354\n",
      "Iteration 5920 : Loss 2981.9769\n",
      "Iteration 5930 : Loss 2981.6202\n",
      "Iteration 5940 : Loss 2981.2650\n",
      "Iteration 5950 : Loss 2980.9115\n",
      "Iteration 5960 : Loss 2980.5597\n",
      "Iteration 5970 : Loss 2980.2095\n",
      "Iteration 5980 : Loss 2979.8608\n",
      "Iteration 5990 : Loss 2979.5138\n",
      "Iteration 6000 : Loss 2979.1684\n",
      "Iteration 6010 : Loss 2978.8246\n",
      "Iteration 6020 : Loss 2978.4823\n",
      "Iteration 6030 : Loss 2978.1417\n",
      "Iteration 6040 : Loss 2977.8026\n",
      "Iteration 6050 : Loss 2977.4650\n",
      "Iteration 6060 : Loss 2977.1290\n",
      "Iteration 6070 : Loss 2976.7946\n",
      "Iteration 6080 : Loss 2976.4617\n",
      "Iteration 6090 : Loss 2976.1303\n",
      "Iteration 6100 : Loss 2975.8004\n",
      "Iteration 6110 : Loss 2975.4721\n",
      "Iteration 6120 : Loss 2975.1452\n",
      "Iteration 6130 : Loss 2974.8199\n",
      "Iteration 6140 : Loss 2974.4960\n",
      "Iteration 6150 : Loss 2974.1736\n",
      "Iteration 6160 : Loss 2973.8527\n",
      "Iteration 6170 : Loss 2973.5333\n",
      "Iteration 6180 : Loss 2973.2154\n",
      "Iteration 6190 : Loss 2972.8989\n",
      "Iteration 6200 : Loss 2972.5838\n",
      "Iteration 6210 : Loss 2972.2702\n",
      "Iteration 6220 : Loss 2971.9580\n",
      "Iteration 6230 : Loss 2971.6472\n",
      "Iteration 6240 : Loss 2971.3379\n",
      "Iteration 6250 : Loss 2971.0300\n",
      "Iteration 6260 : Loss 2970.7234\n",
      "Iteration 6270 : Loss 2970.4183\n",
      "Iteration 6280 : Loss 2970.1146\n",
      "Iteration 6290 : Loss 2969.8122\n",
      "Iteration 6300 : Loss 2969.5113\n",
      "Iteration 6310 : Loss 2969.2117\n",
      "Iteration 6320 : Loss 2968.9134\n",
      "Iteration 6330 : Loss 2968.6165\n",
      "Iteration 6340 : Loss 2968.3210\n",
      "Iteration 6350 : Loss 2968.0268\n",
      "Iteration 6360 : Loss 2967.7340\n",
      "Iteration 6370 : Loss 2967.4425\n",
      "Iteration 6380 : Loss 2967.1523\n",
      "Iteration 6390 : Loss 2966.8634\n",
      "Iteration 6400 : Loss 2966.5759\n",
      "Iteration 6410 : Loss 2966.2896\n",
      "Iteration 6420 : Loss 2966.0047\n",
      "Iteration 6430 : Loss 2965.7210\n",
      "Iteration 6440 : Loss 2965.4386\n",
      "Iteration 6450 : Loss 2965.1575\n",
      "Iteration 6460 : Loss 2964.8777\n",
      "Iteration 6470 : Loss 2964.5992\n",
      "Iteration 6480 : Loss 2964.3219\n",
      "Iteration 6490 : Loss 2964.0458\n",
      "Iteration 6500 : Loss 2963.7711\n",
      "Iteration 6510 : Loss 2963.4975\n",
      "Iteration 6520 : Loss 2963.2252\n",
      "Iteration 6530 : Loss 2962.9542\n",
      "Iteration 6540 : Loss 2962.6843\n",
      "Iteration 6550 : Loss 2962.4157\n",
      "Iteration 6560 : Loss 2962.1483\n",
      "Iteration 6570 : Loss 2961.8821\n",
      "Iteration 6580 : Loss 2961.6171\n",
      "Iteration 6590 : Loss 2961.3532\n",
      "Iteration 6600 : Loss 2961.0906\n",
      "Iteration 6610 : Loss 2960.8292\n",
      "Iteration 6620 : Loss 2960.5689\n",
      "Iteration 6630 : Loss 2960.3099\n",
      "Iteration 6640 : Loss 2960.0519\n",
      "Iteration 6650 : Loss 2959.7952\n",
      "Iteration 6660 : Loss 2959.5396\n",
      "Iteration 6670 : Loss 2959.2851\n",
      "Iteration 6680 : Loss 2959.0318\n",
      "Iteration 6690 : Loss 2958.7797\n",
      "Iteration 6700 : Loss 2958.5286\n",
      "Iteration 6710 : Loss 2958.2787\n",
      "Iteration 6720 : Loss 2958.0300\n",
      "Iteration 6730 : Loss 2957.7823\n",
      "Iteration 6740 : Loss 2957.5358\n",
      "Iteration 6750 : Loss 2957.2903\n",
      "Iteration 6760 : Loss 2957.0460\n",
      "Iteration 6770 : Loss 2956.8027\n",
      "Iteration 6780 : Loss 2956.5606\n",
      "Iteration 6790 : Loss 2956.3195\n",
      "Iteration 6800 : Loss 2956.0795\n",
      "Iteration 6810 : Loss 2955.8406\n",
      "Iteration 6820 : Loss 2955.6027\n",
      "Iteration 6830 : Loss 2955.3660\n",
      "Iteration 6840 : Loss 2955.1302\n",
      "Iteration 6850 : Loss 2954.8956\n",
      "Iteration 6860 : Loss 2954.6620\n",
      "Iteration 6870 : Loss 2954.4294\n",
      "Iteration 6880 : Loss 2954.1979\n",
      "Iteration 6890 : Loss 2953.9674\n",
      "Iteration 6900 : Loss 2953.7379\n",
      "Iteration 6910 : Loss 2953.5095\n",
      "Iteration 6920 : Loss 2953.2820\n",
      "Iteration 6930 : Loss 2953.0556\n",
      "Iteration 6940 : Loss 2952.8302\n",
      "Iteration 6950 : Loss 2952.6058\n",
      "Iteration 6960 : Loss 2952.3824\n",
      "Iteration 6970 : Loss 2952.1600\n",
      "Iteration 6980 : Loss 2951.9386\n",
      "Iteration 6990 : Loss 2951.7182\n",
      "Iteration 7000 : Loss 2951.4987\n",
      "Iteration 7010 : Loss 2951.2803\n",
      "Iteration 7020 : Loss 2951.0628\n",
      "Iteration 7030 : Loss 2950.8463\n",
      "Iteration 7040 : Loss 2950.6307\n",
      "Iteration 7050 : Loss 2950.4161\n",
      "Iteration 7060 : Loss 2950.2024\n",
      "Iteration 7070 : Loss 2949.9897\n",
      "Iteration 7080 : Loss 2949.7780\n",
      "Iteration 7090 : Loss 2949.5671\n",
      "Iteration 7100 : Loss 2949.3573\n",
      "Iteration 7110 : Loss 2949.1483\n",
      "Iteration 7120 : Loss 2948.9403\n",
      "Iteration 7130 : Loss 2948.7332\n",
      "Iteration 7140 : Loss 2948.5270\n",
      "Iteration 7150 : Loss 2948.3217\n",
      "Iteration 7160 : Loss 2948.1173\n",
      "Iteration 7170 : Loss 2947.9139\n",
      "Iteration 7180 : Loss 2947.7113\n",
      "Iteration 7190 : Loss 2947.5097\n",
      "Iteration 7200 : Loss 2947.3089\n",
      "Iteration 7210 : Loss 2947.1090\n",
      "Iteration 7220 : Loss 2946.9100\n",
      "Iteration 7230 : Loss 2946.7119\n",
      "Iteration 7240 : Loss 2946.5146\n",
      "Iteration 7250 : Loss 2946.3182\n",
      "Iteration 7260 : Loss 2946.1227\n",
      "Iteration 7270 : Loss 2945.9281\n",
      "Iteration 7280 : Loss 2945.7343\n",
      "Iteration 7290 : Loss 2945.5413\n",
      "Iteration 7300 : Loss 2945.3492\n",
      "Iteration 7310 : Loss 2945.1580\n",
      "Iteration 7320 : Loss 2944.9676\n",
      "Iteration 7330 : Loss 2944.7780\n",
      "Iteration 7340 : Loss 2944.5893\n",
      "Iteration 7350 : Loss 2944.4014\n",
      "Iteration 7360 : Loss 2944.2144\n",
      "Iteration 7370 : Loss 2944.0281\n",
      "Iteration 7380 : Loss 2943.8427\n",
      "Iteration 7390 : Loss 2943.6581\n",
      "Iteration 7400 : Loss 2943.4743\n",
      "Iteration 7410 : Loss 2943.2913\n",
      "Iteration 7420 : Loss 2943.1091\n",
      "Iteration 7430 : Loss 2942.9277\n",
      "Iteration 7440 : Loss 2942.7471\n",
      "Iteration 7450 : Loss 2942.5673\n",
      "Iteration 7460 : Loss 2942.3882\n",
      "Iteration 7470 : Loss 2942.2100\n",
      "Iteration 7480 : Loss 2942.0326\n",
      "Iteration 7490 : Loss 2941.8559\n",
      "Iteration 7500 : Loss 2941.6800\n",
      "Iteration 7510 : Loss 2941.5048\n",
      "Iteration 7520 : Loss 2941.3305\n",
      "Iteration 7530 : Loss 2941.1569\n",
      "Iteration 7540 : Loss 2940.9840\n",
      "Iteration 7550 : Loss 2940.8119\n",
      "Iteration 7560 : Loss 2940.6406\n",
      "Iteration 7570 : Loss 2940.4700\n",
      "Iteration 7580 : Loss 2940.3002\n",
      "Iteration 7590 : Loss 2940.1310\n",
      "Iteration 7600 : Loss 2939.9627\n",
      "Iteration 7610 : Loss 2939.7950\n",
      "Iteration 7620 : Loss 2939.6281\n",
      "Iteration 7630 : Loss 2939.4620\n",
      "Iteration 7640 : Loss 2939.2965\n",
      "Iteration 7650 : Loss 2939.1318\n",
      "Iteration 7660 : Loss 2938.9678\n",
      "Iteration 7670 : Loss 2938.8045\n",
      "Iteration 7680 : Loss 2938.6419\n",
      "Iteration 7690 : Loss 2938.4800\n",
      "Iteration 7700 : Loss 2938.3188\n",
      "Iteration 7710 : Loss 2938.1583\n",
      "Iteration 7720 : Loss 2937.9986\n",
      "Iteration 7730 : Loss 2937.8395\n",
      "Iteration 7740 : Loss 2937.6811\n",
      "Iteration 7750 : Loss 2937.5234\n",
      "Iteration 7760 : Loss 2937.3663\n",
      "Iteration 7770 : Loss 2937.2100\n",
      "Iteration 7780 : Loss 2937.0543\n",
      "Iteration 7790 : Loss 2936.8994\n",
      "Iteration 7800 : Loss 2936.7450\n",
      "Iteration 7810 : Loss 2936.5914\n",
      "Iteration 7820 : Loss 2936.4384\n",
      "Iteration 7830 : Loss 2936.2861\n",
      "Iteration 7840 : Loss 2936.1344\n",
      "Iteration 7850 : Loss 2935.9834\n",
      "Iteration 7860 : Loss 2935.8330\n",
      "Iteration 7870 : Loss 2935.6833\n",
      "Iteration 7880 : Loss 2935.5343\n",
      "Iteration 7890 : Loss 2935.3859\n",
      "Iteration 7900 : Loss 2935.2381\n",
      "Iteration 7910 : Loss 2935.0910\n",
      "Iteration 7920 : Loss 2934.9445\n",
      "Iteration 7930 : Loss 2934.7986\n",
      "Iteration 7940 : Loss 2934.6533\n",
      "Iteration 7950 : Loss 2934.5087\n",
      "Iteration 7960 : Loss 2934.3647\n",
      "Iteration 7970 : Loss 2934.2214\n",
      "Iteration 7980 : Loss 2934.0786\n",
      "Iteration 7990 : Loss 2933.9365\n",
      "Iteration 8000 : Loss 2933.7949\n",
      "Iteration 8010 : Loss 2933.6540\n",
      "Iteration 8020 : Loss 2933.5137\n",
      "Iteration 8030 : Loss 2933.3740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 8040 : Loss 2933.2349\n",
      "Iteration 8050 : Loss 2933.0964\n",
      "Iteration 8060 : Loss 2932.9585\n",
      "Iteration 8070 : Loss 2932.8211\n",
      "Iteration 8080 : Loss 2932.6844\n",
      "Iteration 8090 : Loss 2932.5483\n",
      "Iteration 8100 : Loss 2932.4127\n",
      "Iteration 8110 : Loss 2932.2777\n",
      "Iteration 8120 : Loss 2932.1433\n",
      "Iteration 8130 : Loss 2932.0095\n",
      "Iteration 8140 : Loss 2931.8762\n",
      "Iteration 8150 : Loss 2931.7435\n",
      "Iteration 8160 : Loss 2931.6114\n",
      "Iteration 8170 : Loss 2931.4799\n",
      "Iteration 8180 : Loss 2931.3489\n",
      "Iteration 8190 : Loss 2931.2184\n",
      "Iteration 8200 : Loss 2931.0886\n",
      "Iteration 8210 : Loss 2930.9593\n",
      "Iteration 8220 : Loss 2930.8305\n",
      "Iteration 8230 : Loss 2930.7023\n",
      "Iteration 8240 : Loss 2930.5746\n",
      "Iteration 8250 : Loss 2930.4475\n",
      "Iteration 8260 : Loss 2930.3209\n",
      "Iteration 8270 : Loss 2930.1948\n",
      "Iteration 8280 : Loss 2930.0693\n",
      "Iteration 8290 : Loss 2929.9444\n",
      "Iteration 8300 : Loss 2929.8199\n",
      "Iteration 8310 : Loss 2929.6960\n",
      "Iteration 8320 : Loss 2929.5726\n",
      "Iteration 8330 : Loss 2929.4498\n",
      "Iteration 8340 : Loss 2929.3274\n",
      "Iteration 8350 : Loss 2929.2056\n",
      "Iteration 8360 : Loss 2929.0843\n",
      "Iteration 8370 : Loss 2928.9635\n",
      "Iteration 8380 : Loss 2928.8433\n",
      "Iteration 8390 : Loss 2928.7235\n",
      "Iteration 8400 : Loss 2928.6043\n",
      "Iteration 8410 : Loss 2928.4855\n",
      "Iteration 8420 : Loss 2928.3673\n",
      "Iteration 8430 : Loss 2928.2495\n",
      "Iteration 8440 : Loss 2928.1323\n",
      "Iteration 8450 : Loss 2928.0156\n",
      "Iteration 8460 : Loss 2927.8993\n",
      "Iteration 8470 : Loss 2927.7835\n",
      "Iteration 8480 : Loss 2927.6683\n",
      "Iteration 8490 : Loss 2927.5535\n",
      "Iteration 8500 : Loss 2927.4392\n",
      "Iteration 8510 : Loss 2927.3254\n",
      "Iteration 8520 : Loss 2927.2121\n",
      "Iteration 8530 : Loss 2927.0992\n",
      "Iteration 8540 : Loss 2926.9868\n",
      "Iteration 8550 : Loss 2926.8749\n",
      "Iteration 8560 : Loss 2926.7635\n",
      "Iteration 8570 : Loss 2926.6525\n",
      "Iteration 8580 : Loss 2926.5420\n",
      "Iteration 8590 : Loss 2926.4320\n",
      "Iteration 8600 : Loss 2926.3224\n",
      "Iteration 8610 : Loss 2926.2133\n",
      "Iteration 8620 : Loss 2926.1047\n",
      "Iteration 8630 : Loss 2925.9965\n",
      "Iteration 8640 : Loss 2925.8888\n",
      "Iteration 8650 : Loss 2925.7815\n",
      "Iteration 8660 : Loss 2925.6747\n",
      "Iteration 8670 : Loss 2925.5683\n",
      "Iteration 8680 : Loss 2925.4624\n",
      "Iteration 8690 : Loss 2925.3569\n",
      "Iteration 8700 : Loss 2925.2518\n",
      "Iteration 8710 : Loss 2925.1472\n",
      "Iteration 8720 : Loss 2925.0431\n",
      "Iteration 8730 : Loss 2924.9393\n",
      "Iteration 8740 : Loss 2924.8361\n",
      "Iteration 8750 : Loss 2924.7332\n",
      "Iteration 8760 : Loss 2924.6308\n",
      "Iteration 8770 : Loss 2924.5288\n",
      "Iteration 8780 : Loss 2924.4272\n",
      "Iteration 8790 : Loss 2924.3260\n",
      "Iteration 8800 : Loss 2924.2253\n",
      "Iteration 8810 : Loss 2924.1250\n",
      "Iteration 8820 : Loss 2924.0251\n",
      "Iteration 8830 : Loss 2923.9257\n",
      "Iteration 8840 : Loss 2923.8266\n",
      "Iteration 8850 : Loss 2923.7280\n",
      "Iteration 8860 : Loss 2923.6297\n",
      "Iteration 8870 : Loss 2923.5319\n",
      "Iteration 8880 : Loss 2923.4345\n",
      "Iteration 8890 : Loss 2923.3375\n",
      "Iteration 8900 : Loss 2923.2409\n",
      "Iteration 8910 : Loss 2923.1447\n",
      "Iteration 8920 : Loss 2923.0489\n",
      "Iteration 8930 : Loss 2922.9535\n",
      "Iteration 8940 : Loss 2922.8585\n",
      "Iteration 8950 : Loss 2922.7639\n",
      "Iteration 8960 : Loss 2922.6697\n",
      "Iteration 8970 : Loss 2922.5759\n",
      "Iteration 8980 : Loss 2922.4824\n",
      "Iteration 8990 : Loss 2922.3894\n",
      "Iteration 9000 : Loss 2922.2967\n",
      "Iteration 9010 : Loss 2922.2045\n",
      "Iteration 9020 : Loss 2922.1126\n",
      "Iteration 9030 : Loss 2922.0211\n",
      "Iteration 9040 : Loss 2921.9299\n",
      "Iteration 9050 : Loss 2921.8392\n",
      "Iteration 9060 : Loss 2921.7488\n",
      "Iteration 9070 : Loss 2921.6588\n",
      "Iteration 9080 : Loss 2921.5692\n",
      "Iteration 9090 : Loss 2921.4799\n",
      "Iteration 9100 : Loss 2921.3910\n",
      "Iteration 9110 : Loss 2921.3025\n",
      "Iteration 9120 : Loss 2921.2144\n",
      "Iteration 9130 : Loss 2921.1266\n",
      "Iteration 9140 : Loss 2921.0391\n",
      "Iteration 9150 : Loss 2920.9521\n",
      "Iteration 9160 : Loss 2920.8654\n",
      "Iteration 9170 : Loss 2920.7790\n",
      "Iteration 9180 : Loss 2920.6930\n",
      "Iteration 9190 : Loss 2920.6074\n",
      "Iteration 9200 : Loss 2920.5221\n",
      "Iteration 9210 : Loss 2920.4372\n",
      "Iteration 9220 : Loss 2920.3526\n",
      "Iteration 9230 : Loss 2920.2683\n",
      "Iteration 9240 : Loss 2920.1844\n",
      "Iteration 9250 : Loss 2920.1009\n",
      "Iteration 9260 : Loss 2920.0177\n",
      "Iteration 9270 : Loss 2919.9348\n",
      "Iteration 9280 : Loss 2919.8523\n",
      "Iteration 9290 : Loss 2919.7701\n",
      "Iteration 9300 : Loss 2919.6883\n",
      "Iteration 9310 : Loss 2919.6068\n",
      "Iteration 9320 : Loss 2919.5256\n",
      "Iteration 9330 : Loss 2919.4447\n",
      "Iteration 9340 : Loss 2919.3642\n",
      "Iteration 9350 : Loss 2919.2840\n",
      "Iteration 9360 : Loss 2919.2042\n",
      "Iteration 9370 : Loss 2919.1247\n",
      "Iteration 9380 : Loss 2919.0455\n",
      "Iteration 9390 : Loss 2918.9666\n",
      "Iteration 9400 : Loss 2918.8880\n",
      "Iteration 9410 : Loss 2918.8098\n",
      "Iteration 9420 : Loss 2918.7319\n",
      "Iteration 9430 : Loss 2918.6543\n",
      "Iteration 9440 : Loss 2918.5770\n",
      "Iteration 9450 : Loss 2918.5001\n",
      "Iteration 9460 : Loss 2918.4234\n",
      "Iteration 9470 : Loss 2918.3471\n",
      "Iteration 9480 : Loss 2918.2710\n",
      "Iteration 9490 : Loss 2918.1953\n",
      "Iteration 9500 : Loss 2918.1199\n",
      "Iteration 9510 : Loss 2918.0448\n",
      "Iteration 9520 : Loss 2917.9700\n",
      "Iteration 9530 : Loss 2917.8955\n",
      "Iteration 9540 : Loss 2917.8213\n",
      "Iteration 9550 : Loss 2917.7475\n",
      "Iteration 9560 : Loss 2917.6739\n",
      "Iteration 9570 : Loss 2917.6006\n",
      "Iteration 9580 : Loss 2917.5276\n",
      "Iteration 9590 : Loss 2917.4549\n",
      "Iteration 9600 : Loss 2917.3825\n",
      "Iteration 9610 : Loss 2917.3104\n",
      "Iteration 9620 : Loss 2917.2386\n",
      "Iteration 9630 : Loss 2917.1671\n",
      "Iteration 9640 : Loss 2917.0958\n",
      "Iteration 9650 : Loss 2917.0249\n",
      "Iteration 9660 : Loss 2916.9542\n",
      "Iteration 9670 : Loss 2916.8839\n",
      "Iteration 9680 : Loss 2916.8138\n",
      "Iteration 9690 : Loss 2916.7440\n",
      "Iteration 9700 : Loss 2916.6745\n",
      "Iteration 9710 : Loss 2916.6052\n",
      "Iteration 9720 : Loss 2916.5363\n",
      "Iteration 9730 : Loss 2916.4676\n",
      "Iteration 9740 : Loss 2916.3992\n",
      "Iteration 9750 : Loss 2916.3310\n",
      "Iteration 9760 : Loss 2916.2632\n",
      "Iteration 9770 : Loss 2916.1956\n",
      "Iteration 9780 : Loss 2916.1283\n",
      "Iteration 9790 : Loss 2916.0613\n",
      "Iteration 9800 : Loss 2915.9945\n",
      "Iteration 9810 : Loss 2915.9280\n",
      "Iteration 9820 : Loss 2915.8618\n",
      "Iteration 9830 : Loss 2915.7958\n",
      "Iteration 9840 : Loss 2915.7301\n",
      "Iteration 9850 : Loss 2915.6647\n",
      "Iteration 9860 : Loss 2915.5995\n",
      "Iteration 9870 : Loss 2915.5346\n",
      "Iteration 9880 : Loss 2915.4699\n",
      "Iteration 9890 : Loss 2915.4055\n",
      "Iteration 9900 : Loss 2915.3414\n",
      "Iteration 9910 : Loss 2915.2775\n",
      "Iteration 9920 : Loss 2915.2139\n",
      "Iteration 9930 : Loss 2915.1505\n",
      "Iteration 9940 : Loss 2915.0874\n",
      "Iteration 9950 : Loss 2915.0246\n",
      "Iteration 9960 : Loss 2914.9619\n",
      "Iteration 9970 : Loss 2914.8996\n",
      "Iteration 9980 : Loss 2914.8375\n",
      "Iteration 9990 : Loss 2914.7756\n",
      "Iteration 10000 : Loss 2914.7140\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "\n",
    "#10000 epoch 학습\n",
    "for i in range(1, 10001):\n",
    "    dW, db = gradient(X_train, W, b, y_train)\n",
    "    W -= LEARNING_RATE * dW\n",
    "    b -= LEARNING_RATE * db\n",
    "    L = loss(X_train, W, b, y_train)\n",
    "    losses.append(L)\n",
    "    if i % 10 == 0:\n",
    "        print('Iteration %d : Loss %0.4f' % (i, L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6b13296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c89f680",
   "metadata": {},
   "source": [
    "# test 데이터에 대한 성능 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33b232f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2866.9641472250196"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = model(X_test, W, b)\n",
    "mse = loss(X_test, W, b, y_test)\n",
    "mse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d437407",
   "metadata": {},
   "source": [
    "# 정답 데이터와 예측한 데이터 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45d8dbe5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X_test[:, 0], y_test, label=\"True\")\n",
    "plt.scatter(X_test[:, 0], prediction, label=\"Pred\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
